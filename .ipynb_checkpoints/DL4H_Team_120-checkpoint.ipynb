{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j01aH0PR4Sg-"
   },
   "source": [
    "# Before you use this template\n",
    "\n",
    "This template is just a recommended template for project Report. It only considers the general type of research in our paper pool. Feel free to edit it to better fit your project. You will iteratively update the same notebook submission for your draft and the final submission. Please check the project rubriks to get a sense of what is expected in the template.\n",
    "\n",
    "---\n",
    "\n",
    "# FAQ and Attentions\n",
    "* Copy and move this template to your Google Drive. Name your notebook by your team ID (upper-left corner). Don't eidt this original file.\n",
    "* This template covers most questions we want to ask about your reproduction experiment. You don't need to exactly follow the template, however, you should address the questions. Please feel free to customize your report accordingly.\n",
    "* any report must have run-able codes and necessary annotations (in text and code comments).\n",
    "* The notebook is like a demo and only uses small-size data (a subset of original data or processed data), the entire runtime of the notebook including data reading, data process, model training, printing, figure plotting, etc,\n",
    "must be within 8 min, otherwise, you may get penalty on the grade.\n",
    "  * If the raw dataset is too large to be loaded  you can select a subset of data and pre-process the data, then, upload the subset or processed data to Google Drive and load them in this notebook.\n",
    "  * If the whole training is too long to run, you can only set the number of training epoch to a small number, e.g., 3, just show that the training is runable.\n",
    "  * For results model validation, you can train the model outside this notebook in advance, then, load pretrained model and use it for validation (display the figures, print the metrics).\n",
    "* The post-process is important! For post-process of the results,please use plots/figures. The code to summarize results and plot figures may be tedious, however, it won't be waste of time since these figures can be used for presentation. While plotting in code, the figures should have titles or captions if necessary (e.g., title your figure with \"Figure 1. xxxx\")\n",
    "* There is not page limit to your notebook report, you can also use separate notebooks for the report, just make sure your grader can access and run/test them.\n",
    "* If you use outside resources, please refer them (in any formats). Include the links to the resources if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlv6knX04FiY"
   },
   "source": [
    "# Mount Notebook to Google Drive\n",
    "Upload the data, pretrianed model, figures, etc to your Google Drive, then mount this notebook to Google Drive. After that, you can access the resources freely.\n",
    "\n",
    "Instruction: https://colab.research.google.com/notebooks/io.ipynb\n",
    "\n",
    "Example: https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q\n",
    "\n",
    "Video: https://www.youtube.com/watch?v=zc8g8lGcwQU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sfk8Zrul_E8V"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "This is an introduction to your report, you should edit this text/mardown section to compose. In this text/markdown, you should introduce:\n",
    "\n",
    "*   Background of the problem\n",
    "  1. what type of problem: disease/readmission/mortality prediction,  feature engineeing, data processing, etc\n",
    "  2. what is the importance/meaning of solving the problem\n",
    "  3. what is the difficulty of the problem\n",
    "  4. the state of the art methods and effectiveness.\n",
    "*   Paper explanation\n",
    "  1. what did the paper propose\n",
    "  2. what is the innovations of the method\n",
    "  3. how well the proposed method work (in its own metrics)\n",
    "  4. what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background of the problem\n",
    "Graph-structured data are ubiquitous in various applications of healthcare domain, such as protein-protein interaction (PPI) prediction and drug-drug interaction (DDI) prediction. Graph Attention Networks (GAT) (Velickovic et al., 2018), as one of the most popular Graph Neural Networks (GNNs), has been widely adopted in these applications due to its ability to effectively model relationships between nodes in a graph. In this project, we are trying to explore the role of GAT in healthcare domains. \n",
    "\n",
    "[add more details]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ABD4VhFZbehA"
   },
   "outputs": [],
   "source": [
    "# code comment is used as inline annotations for your coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygL9tTPSVHB"
   },
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
    "\n",
    "\n",
    "1.   Hypothesis 1: attention mechanism greatly improves the performace of GAT for most of the time;\n",
    "2.   Hypothesis 2: multi-head benifits the feature extraction process;\n",
    "3.   Hypothesis 3: one of the drawbacks of GAT is that, the attention mechanism is static instead of dynamic (Brody et al., 2022).\n",
    "\n",
    "You can insert images in this notebook text, [see this link](https://stackoverflow.com/questions/50670920/how-to-insert-an-inline-image-in-google-colaboratory-from-google-drive) and example below:\n",
    "\n",
    "![sample_image.png](https://drive.google.com/uc?export=view&id=1g2efvsRJDxTxKz-OY3loMhihrEUdBxbc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM4WUjz64C3B"
   },
   "source": [
    "\n",
    "You can also use code to display images, see the code below.\n",
    "\n",
    "The images must be saved in Google Drive first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWAHJ_1CdtaA"
   },
   "source": [
    "# Methodology\n",
    "\n",
    "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
    "\n",
    "The methodology at least contains two subsections **data** and **model** in your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "##  Data\n",
    "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
    "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
    "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
    "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
    "  * Illustration: printing results, plotting figures for illustration.\n",
    "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzVUQS0CHry0"
   },
   "source": [
    "## Data 1: Drug-drug Interaction (DDI) Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train\n",
      "Number of samples: 115185\n",
      "Number of drugs: 1671\n",
      "Number of interactions: 86\n",
      "**************************************************\n",
      "Split: val\n",
      "Number of samples: 38348\n",
      "Number of drugs: 1582\n",
      "Number of interactions: 86\n",
      "**************************************************\n",
      "Split: test\n",
      "Number of samples: 38337\n",
      "Number of drugs: 1597\n",
      "Number of interactions: 86\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# dir and function to load raw data\n",
    "raw_data_dir = 'data/drug_interaction'\n",
    "\n",
    "def load_data(raw_data_dir):\n",
    "    # implement this function to load raw data to dataframe/numpy array/tensor\n",
    "    \n",
    "    df_ddi_train = pd.read_csv(os.path.join(raw_data_dir, 'ddi_training.csv'))\n",
    "    df_ddi_val = pd.read_csv(os.path.join(raw_data_dir, 'ddi_validation.csv'))\n",
    "    df_ddi_test = pd.read_csv(os.path.join(raw_data_dir, 'ddi_test.csv'))\n",
    "\n",
    "    return df_ddi_train, df_ddi_val, df_ddi_test\n",
    "\n",
    "\n",
    "df_ddi_train, df_ddi_val, df_ddi_test = load_data(raw_data_dir)\n",
    "\n",
    "# calculate statistics\n",
    "def calculate_stats(df_ddi, split):\n",
    "    # implement this function to calculate the statistics\n",
    "    # it is encouraged to print out the results\n",
    "\n",
    "    # statistics for the dataset\n",
    "    # (1) number of samples; (2) number of drugs [set for d1 and d2]; (3) number of drug interactions [type]\n",
    "    num_samples = df_ddi.shape[0]\n",
    "    num_drugs = len(set(df_ddi['d1'].values) | set(df_ddi['d2'].values))\n",
    "    num_interactions = len(set(df_ddi['type'].values))\n",
    "    \n",
    "    print(f'Split: {split}')\n",
    "    print(f'Number of samples: {num_samples}')\n",
    "    print(f'Number of drugs: {num_drugs}')\n",
    "    print(f'Number of interactions: {num_interactions}')\n",
    "    print('*' * 50)\n",
    "\n",
    "\n",
    "calculate_stats(df_ddi_train, 'train')\n",
    "calculate_stats(df_ddi_val, 'val')\n",
    "calculate_stats(df_ddi_test, 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tup_ddi = [(h, t, r) for h, t, r in zip(df_ddi_train['d1'], df_ddi_train['d2'], df_ddi_train['type'])]\n",
    "val_tup_ddi = [(h, t, r) for h, t, r in zip(df_ddi_val['d1'], df_ddi_val['d2'], df_ddi_val['type'])]\n",
    "test_tup_ddi = [(h, t, r) for h, t, r in zip(df_ddi_test['d1'], df_ddi_test['d2'], df_ddi_test['type'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 2: Protein-protein Interaction (PPI) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train\n",
      "Number of graphs: 20\n",
      "Number of nodes: 44906\n",
      "Number of edges: 1226368\n",
      "Number of features: 50\n",
      "Number of classes: 121\n",
      "**************************************************\n",
      "Split: val\n",
      "Number of graphs: 2\n",
      "Number of nodes: 6514\n",
      "Number of edges: 198920\n",
      "Number of features: 50\n",
      "Number of classes: 121\n",
      "**************************************************\n",
      "Split: test\n",
      "Number of graphs: 2\n",
      "Number of nodes: 5524\n",
      "Number of edges: 161976\n",
      "Number of features: 50\n",
      "Number of classes: 121\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def load_data(data_dir):\n",
    "    path = data_dir\n",
    "    train_dataset = PPI(path, split='train')\n",
    "    val_dataset = PPI(path, split='val')\n",
    "    test_dataset = PPI(path, split='test')\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "train_dataset_ppi, val_dataset_ppi, test_dataset_ppi = load_data('data/ppi')\n",
    "\n",
    "\n",
    "# outut the statistics\n",
    "def calculate_stats(dataset, split):\n",
    "    # Initialize counters\n",
    "    num_graphs = len(dataset)\n",
    "    num_nodes = 0\n",
    "    num_edges = 0\n",
    "\n",
    "    # Loop through the dataset to accumulate statistics\n",
    "    for data in dataset:\n",
    "        num_nodes += data.num_nodes\n",
    "        num_edges += data.num_edges\n",
    "    \n",
    "    # Since features and classes are consistent across the dataset, we can take them from the first graph\n",
    "    num_features = dataset[0].num_features\n",
    "    num_classes = dataset[0].y.size(1)  # Assuming the labels are one-hot encoded\n",
    "\n",
    "    print(f'Split: {split}')\n",
    "    print(f'Number of graphs: {num_graphs}')\n",
    "    print(f'Number of nodes: {num_nodes}')\n",
    "    print(f'Number of edges: {num_edges}')\n",
    "    print(f'Number of features: {num_features}')\n",
    "    print(f'Number of classes: {num_classes}')\n",
    "    print('*' * 50)\n",
    "\n",
    "calculate_stats(train_dataset_ppi, 'train')\n",
    "calculate_stats(val_dataset_ppi, 'val')\n",
    "calculate_stats(test_dataset_ppi, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 3: PubMed Citation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train\n",
      "Statistics for the citation network:\n",
      "Number of graphs: 1\n",
      "Number of nodes: 19717\n",
      "Number of edges: 37676\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "**************************************************\n",
      "Split: val\n",
      "Statistics for the citation network:\n",
      "Number of graphs: 1\n",
      "Number of nodes: 19717\n",
      "Number of edges: 37676\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "**************************************************\n",
      "Split: test\n",
      "Statistics for the citation network:\n",
      "Number of graphs: 1\n",
      "Number of nodes: 19717\n",
      "Number of edges: 39892\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import CitationFull\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "def load_pubmed_data(data_dir):\n",
    "    dataset = CitationFull(root=data_dir, name='PubMed', transform=transform)\n",
    "    train_data, val_data, test_data = dataset[0]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "train_data_pubmed, val_data_pubmed, test_data_pubmed = load_pubmed_data('data/pubmed')\n",
    "\n",
    "def calculate_stats_citation(dataset, split):\n",
    "    # For citation networks processed by RandomLinkSplit, we typically have one graph represented by edge splits.\n",
    "    num_nodes = dataset.num_nodes  # Total number of nodes in the dataset\n",
    "    num_edges = dataset['edge_index'].size(1) // 2  # Divided by 2 for undirected graphs\n",
    "    num_features = dataset.num_features  # Number of features per node\n",
    "    num_classes = dataset.y.unique().size(0)  # Assuming 'y' holds class labels for nodes\n",
    "    # Print the statistics\n",
    "    print(f'Split: {split}')\n",
    "    print(\"Statistics for the citation network:\")\n",
    "    print(f\"Number of graphs: 1\")\n",
    "    print(f\"Number of nodes: {num_nodes}\")\n",
    "    print(f\"Number of edges: {num_edges}\")\n",
    "    print(f\"Number of features: {num_features}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print('*' * 50)\n",
    "\n",
    "\n",
    "calculate_stats_citation(train_data_pubmed, 'train')\n",
    "calculate_stats_citation(val_data_pubmed, 'val')\n",
    "calculate_stats_citation(test_data_pubmed, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3muyDPFPbozY"
   },
   "source": [
    "##   Model\n",
    "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
    "  * Model architecture: layer number/size/type, activation function, etc\n",
    "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
    "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
    "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
    "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    if not os.path.exists('./ckpt'):\n",
    "        os.makedirs('./ckpt')\n",
    "    torch.save(state, f'./ckpt/{filename}.pth')\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler, filename):\n",
    "    checkpoint = torch.load(f'./ckpt/{filename}.pth'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if 'scheduler_state_dict' in checkpoint and scheduler:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    return epoch\n",
    "\n",
    "import re\n",
    "\n",
    "def find_last_checkpoint_by_epoch(prefix, checkpoint_dir='ckpt'):\n",
    "    # prefix = task name, ddi, ppi, PubMed-[model]\n",
    "    pattern = re.compile(prefix + r\"_e(\\d{3}).pth\")\n",
    "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if os.path.isfile(os.path.join(checkpoint_dir, f)) and pattern.match(f)]\n",
    "    epochs = [(int(pattern.search(f).group(1)), f) for f in checkpoint_files]\n",
    "    if epochs:\n",
    "        max_epoch_file = max(epochs, key=lambda x: x[0])[1]\n",
    "        return os.path.join(checkpoint_dir, max_epoch_file)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Training GAT for Drug-drug Interaction\n",
    "The input and output for DDI prediction is\n",
    "* Input: Concat[Drug A, Drug B, relation]\n",
    "* Output: Predicted Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cindy2000_sh/uiuc-cs598-team120/utils_ddi.py:109: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return undirected_edge_list.T, features\n"
     ]
    }
   ],
   "source": [
    "from utils_ddi import DrugDataset, DrugDataLoader, TOTAL_ATOM_FEATS\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "n_atom_feats = TOTAL_ATOM_FEATS\n",
    "n_atom_hid = 64\n",
    "rel_total = 86\n",
    "lr = 1e-2\n",
    "weight_decay = 5e-4\n",
    "# n_epochs = 300\n",
    "n_epochs = 5\n",
    "neg_samples = 1\n",
    "batch_size = 1024\n",
    "data_size_ratio = 1\n",
    "kge_dim = 64\n",
    "\n",
    "train_data_ddi = DrugDataset(train_tup_ddi, ratio=1, neg_ent=1)\n",
    "val_data_ddi = DrugDataset(val_tup_ddi, ratio=1, disjoint_split=False)\n",
    "test_data_ddi = DrugDataset(test_tup_ddi, disjoint_split=False)\n",
    "\n",
    "train_data_loader_ddi = DrugDataLoader(train_data_ddi, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader_ddi = DrugDataLoader(val_data_ddi, batch_size=batch_size *3)\n",
    "test_data_loader_ddi = DrugDataLoader(test_data_ddi, batch_size=batch_size *3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_compute(model, batch, device, training=True):\n",
    "    '''\n",
    "        *batch: (pos_tri, neg_tri)\n",
    "        *pos/neg_tri: (batch_h, batch_t, batch_r)\n",
    "    '''\n",
    "    probas_pred, ground_truth = [], []\n",
    "    pos_tri, neg_tri = batch\n",
    "    \n",
    "    pos_tri = [tensor.to(device=device) for tensor in pos_tri]\n",
    "    p_score = model(pos_tri)\n",
    "    probas_pred.append(torch.sigmoid(p_score.detach()).cpu())\n",
    "    ground_truth.append(np.ones(len(p_score)))\n",
    "\n",
    "    neg_tri = [tensor.to(device=device) for tensor in neg_tri]\n",
    "    n_score = model(neg_tri)\n",
    "    probas_pred.append(torch.sigmoid(n_score.detach()).cpu())\n",
    "    ground_truth.append(np.zeros(len(n_score)))\n",
    "\n",
    "    probas_pred = np.concatenate(probas_pred)\n",
    "    ground_truth = np.concatenate(ground_truth)\n",
    "\n",
    "    return p_score, n_score, probas_pred, ground_truth\n",
    "\n",
    "def do_compute_metrics(probas_pred, target):\n",
    "\n",
    "    pred = (probas_pred >= 0.5).astype(np.int32)\n",
    "\n",
    "    acc = metrics.accuracy_score(target, pred)\n",
    "    auc_roc = metrics.roc_auc_score(target, probas_pred)\n",
    "    f1_score = metrics.f1_score(target, pred)\n",
    "\n",
    "    p, r, t = metrics.precision_recall_curve(target, probas_pred)\n",
    "    auc_prc = metrics.auc(r, p)\n",
    "\n",
    "    return acc, auc_roc, auc_prc\n",
    "\n",
    "def train(model, train_data_loader, val_data_loader, loss_fn,  optimizer, n_epochs, device, \n",
    "          scheduler=None, starting_epoch=1):\n",
    "    print('Starting training at', datetime.today())\n",
    "    for i in tqdm(range(starting_epoch, n_epochs+1), desc='Epochs'):\n",
    "        start = time.time()\n",
    "        train_loss = 0\n",
    "        train_loss_pos = 0\n",
    "        train_loss_neg = 0\n",
    "        val_loss = 0\n",
    "        val_loss_pos = 0\n",
    "        val_loss_neg = 0\n",
    "        train_probas_pred = []\n",
    "        train_ground_truth = []\n",
    "        val_probas_pred = []\n",
    "        val_ground_truth = []\n",
    "\n",
    "        for batch in train_data_loader:\n",
    "            model.train()\n",
    "            p_score, n_score, probas_pred, ground_truth = do_compute(model, batch, device)\n",
    "            train_probas_pred.append(probas_pred)\n",
    "            train_ground_truth.append(ground_truth)\n",
    "            loss, loss_p, loss_n = loss_fn(p_score, n_score)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * len(p_score)\n",
    "        train_loss /= len(train_data_ddi)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            train_probas_pred = np.concatenate(train_probas_pred)\n",
    "            train_ground_truth = np.concatenate(train_ground_truth)\n",
    "\n",
    "            train_acc, train_auc_roc, train_auc_prc = do_compute_metrics(train_probas_pred, train_ground_truth)\n",
    "\n",
    "            for batch in val_data_loader:\n",
    "                model.eval()\n",
    "                p_score, n_score, probas_pred, ground_truth = do_compute(model, batch, device)\n",
    "                val_probas_pred.append(probas_pred)\n",
    "                val_ground_truth.append(ground_truth)\n",
    "                loss, loss_p, loss_n = loss_fn(p_score, n_score)\n",
    "                val_loss += loss.item() * len(p_score)            \n",
    "\n",
    "            val_loss /= len(val_data_ddi)\n",
    "            val_probas_pred = np.concatenate(val_probas_pred)\n",
    "            val_ground_truth = np.concatenate(val_ground_truth)\n",
    "            val_acc, val_auc_roc, val_auc_prc = do_compute_metrics(val_probas_pred, val_ground_truth)\n",
    "               \n",
    "        if scheduler:\n",
    "            print('scheduling')\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        tqdm.write(f'tr_loss: {train_loss:.4f}, val_loss: {val_loss:.4f},'\n",
    "                   f' tr_acc: {train_acc:.4f}, val_acc: {val_acc:.4f},'\n",
    "                   f' tr_roc: {train_auc_roc:.4f}, val_roc: {val_auc_roc:.4f},'\n",
    "                   f' tr_aupr: {train_auc_prc:.4f}, val_aupr: {val_auc_prc:.4f}' )\n",
    "\n",
    "        if i % 10 == 0 or i == n_epochs:  \n",
    "            save_checkpoint({\n",
    "                'epoch': i,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None, \n",
    "                'metrics': {'train_loss' : train_loss,\n",
    "                           'val_loss' : val_loss,\n",
    "                           'train_acc' : train_acc,\n",
    "                           'val_acc' : val_acc,\n",
    "                           'train_auc_roc' : train_auc_roc,\n",
    "                           'val_auc_roc' : val_auc_roc,\n",
    "                           'train_auprc' : train_auc_prc,\n",
    "                           'val_auprc' : val_auc_prc},\n",
    "            }, filename=f\"ddi_e{str(i).zfill(3)}.pth\")\n",
    "\n",
    "\n",
    "class SigmoidLoss(nn.Module):\n",
    "    def __init__(self, adv_temperature=None):\n",
    "        super().__init__()\n",
    "        self.adv_temperature = adv_temperature\n",
    "    \n",
    "    def forward(self, p_scores, n_scores):\n",
    "        if self.adv_temperature:\n",
    "            weights= F.softmax(self.adv_temperature * n_scores, dim=-1).detach()\n",
    "            n_scores = weights * n_scores\n",
    "        p_loss = - F.logsigmoid(p_scores).mean()\n",
    "        n_loss = - F.logsigmoid(-n_scores).mean()\n",
    "        \n",
    "        return (p_loss + n_loss) / 2, p_loss, n_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2024-04-11 20:25:10.594234\n",
      "Epoch: 1 (75.7153s), train_loss: 0.7319, val_loss: 0.6853, train_acc: 0.5280, val_acc:0.5510\n",
      "\t\ttrain_roc: 0.5333, val_roc: 0.5713, train_auprc: 0.5195, val_auprc: 0.5491\n",
      "Epoch: 2 (77.4255s), train_loss: 0.6842, val_loss: 0.6827, train_acc: 0.5546, val_acc:0.5532\n",
      "\t\ttrain_roc: 0.5749, val_roc: 0.5797, train_auprc: 0.5516, val_auprc: 0.5500\n",
      "Epoch: 3 (72.1416s), train_loss: 0.6817, val_loss: 0.6816, train_acc: 0.5602, val_acc:0.5654\n",
      "\t\ttrain_roc: 0.5818, val_roc: 0.5882, train_auprc: 0.5556, val_auprc: 0.5601\n",
      "Epoch: 4 (72.6609s), train_loss: 0.6815, val_loss: 0.6807, train_acc: 0.5613, val_acc:0.5616\n",
      "\t\ttrain_roc: 0.5836, val_roc: 0.5863, train_auprc: 0.5574, val_auprc: 0.5571\n",
      "Epoch: 5 (69.9705s), train_loss: 0.6812, val_loss: 0.6792, train_acc: 0.5617, val_acc:0.5700\n",
      "\t\ttrain_roc: 0.5845, val_roc: 0.5920, train_auprc: 0.5570, val_auprc: 0.5613\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv, global_mean_pool, LayerNorm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DDIGAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_iterations = 86\n",
    "        self.num_features = 55\n",
    "        self.num_heads = 2\n",
    "        self.initial_norm = LayerNorm(self.num_features)\n",
    "        self.convA = GATConv(self.num_features, 256, heads=self.num_heads)\n",
    "        self.convB = GATConv(self.num_features, 256, heads=self.num_heads)\n",
    "        self.emb = torch.nn.Embedding(self.num_iterations, 256)\n",
    "        self.lin = torch.nn.Linear((2 * self.num_heads + 1)* 256, 1)\n",
    "\n",
    "    def forward(self, tri):\n",
    "        # (pos_h_samples, pos_t_samples, pos_rels)\n",
    "        head, tail, rel = tri\n",
    "        head.x = self.initial_norm(head.x, head.batch)\n",
    "        tail.x = self.initial_norm(tail.x, tail.batch)\n",
    "        head = F.elu(self.convA(head.x, head.edge_index))\n",
    "        tail = F.elu(self.convB(tail.x, tail.edge_index))\n",
    "        head_emb = global_mean_pool(head, tri[0].batch)\n",
    "        tail_emb = global_mean_pool(tail, tri[1].batch)\n",
    "        rel = self.emb(rel)\n",
    "        out = self.lin(torch.cat([head_emb, tail_emb, rel],dim=-1))\n",
    "        return out\n",
    "\n",
    "model = DDIGAT()\n",
    "loss_func = SigmoidLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.96 ** (epoch))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "last_checkpoint = find_last_checkpoint_by_epoch('ckpt')\n",
    "\n",
    "if last_checkpoint:\n",
    "    last_epoch, last_loss = load_checkpoint(model, optimizer, scheduler, last_checkpoint)\n",
    "    print(f\"Resuming training from epoch {last_epoch + 1}\")\n",
    "    train(model, train_data_loader_ddi, val_data_loader_ddi, SigmoidLoss(), optimizer, n_epochs, device, scheduler, starting_epoch=last_epoch + 1)\n",
    "else:\n",
    "    print(\"No checkpoint found, starting training from scratch.\")\n",
    "    train(model, train_data_loader_ddi, val_data_loader_ddi, loss_func, optimizer, n_epochs, device, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Training GAT for Protein-protein Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader_ppi = DataLoader(train_dataset_ppi, batch_size=1, shuffle=True)\n",
    "val_loader_ppi = DataLoader(val_dataset_ppi, batch_size=2, shuffle=False)\n",
    "test_loader_ppi = DataLoader(test_dataset_ppi, batch_size=2, shuffle=False)\n",
    "\n",
    "class PPINet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(train_dataset_ppi.num_features, 256, heads=4)\n",
    "        self.lin1 = torch.nn.Linear(train_dataset_ppi.num_features, 4 * 256)\n",
    "        self.conv2 = GATConv(4 * 256, 256, heads=4)\n",
    "        self.lin2 = torch.nn.Linear(4 * 256, 4 * 256)\n",
    "        self.conv3 = GATConv(4 * 256, train_dataset_ppi.num_classes, heads=6,\n",
    "                             concat=False)\n",
    "        self.lin3 = torch.nn.Linear(4 * 256, train_dataset_ppi.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = self.conv3(x, edge_index) + self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PPINet().to(device)\n",
    "loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader_ppi:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_op(model(data.x, data.edge_index), data.y)\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(train_loader_ppi.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    ys, preds = [], []\n",
    "    for data in loader:\n",
    "        ys.append(data.y)\n",
    "        out = model(data.x.to(device), data.edge_index.to(device))\n",
    "        preds.append((out > 0).float().cpu())\n",
    "\n",
    "    y, pred = torch.cat(ys, dim=0).numpy(), torch.cat(preds, dim=0).numpy()\n",
    "    return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.8356, Val: 0.4992, Test: 0.5027\n",
      "Epoch: 002, Loss: 0.5247, Val: 0.5270, Test: 0.5350\n",
      "Epoch: 003, Loss: 0.4879, Val: 0.5526, Test: 0.5703\n",
      "Epoch: 004, Loss: 0.4459, Val: 0.6365, Test: 0.6534\n",
      "Epoch: 005, Loss: 0.3993, Val: 0.6863, Test: 0.7064\n",
      "Epoch: 006, Loss: 0.3619, Val: 0.6889, Test: 0.7138\n",
      "Epoch: 007, Loss: 0.3159, Val: 0.7636, Test: 0.7893\n",
      "Epoch: 008, Loss: 0.2715, Val: 0.7897, Test: 0.8166\n",
      "Epoch: 009, Loss: 0.2355, Val: 0.8130, Test: 0.8400\n",
      "Epoch: 010, Loss: 0.1989, Val: 0.8506, Test: 0.8761\n",
      "Epoch: 011, Loss: 0.1713, Val: 0.8646, Test: 0.8890\n",
      "Epoch: 012, Loss: 0.1562, Val: 0.8818, Test: 0.9054\n",
      "Epoch: 013, Loss: 0.1259, Val: 0.9016, Test: 0.9227\n",
      "Epoch: 014, Loss: 0.1066, Val: 0.9126, Test: 0.9332\n",
      "Epoch: 015, Loss: 0.0958, Val: 0.9201, Test: 0.9397\n",
      "Epoch: 016, Loss: 0.0834, Val: 0.9288, Test: 0.9461\n",
      "Epoch: 017, Loss: 0.0759, Val: 0.9358, Test: 0.9523\n",
      "Epoch: 018, Loss: 0.0628, Val: 0.9406, Test: 0.9564\n",
      "Epoch: 019, Loss: 0.0599, Val: 0.9428, Test: 0.9585\n",
      "Epoch: 020, Loss: 0.0523, Val: 0.9420, Test: 0.9573\n",
      "Epoch: 021, Loss: 0.0600, Val: 0.9488, Test: 0.9617\n",
      "Epoch: 022, Loss: 0.0462, Val: 0.9550, Test: 0.9681\n",
      "Epoch: 023, Loss: 0.0355, Val: 0.9573, Test: 0.9698\n",
      "Epoch: 024, Loss: 0.0359, Val: 0.9609, Test: 0.9717\n",
      "Epoch: 025, Loss: 0.0302, Val: 0.9641, Test: 0.9748\n",
      "Epoch: 026, Loss: 0.0281, Val: 0.9658, Test: 0.9758\n",
      "Epoch: 027, Loss: 0.0250, Val: 0.9656, Test: 0.9753\n",
      "Epoch: 028, Loss: 0.0232, Val: 0.9668, Test: 0.9762\n",
      "Epoch: 029, Loss: 0.0210, Val: 0.9680, Test: 0.9771\n",
      "Epoch: 030, Loss: 0.0206, Val: 0.9695, Test: 0.9782\n",
      "Epoch: 031, Loss: 0.0190, Val: 0.9703, Test: 0.9785\n",
      "Epoch: 032, Loss: 0.0193, Val: 0.9694, Test: 0.9781\n",
      "Epoch: 033, Loss: 0.0194, Val: 0.9709, Test: 0.9790\n",
      "Epoch: 034, Loss: 0.0169, Val: 0.9699, Test: 0.9784\n",
      "Epoch: 035, Loss: 0.0190, Val: 0.9701, Test: 0.9786\n",
      "Epoch: 036, Loss: 0.0164, Val: 0.9707, Test: 0.9787\n",
      "Epoch: 037, Loss: 0.0161, Val: 0.9724, Test: 0.9801\n",
      "Epoch: 038, Loss: 0.0142, Val: 0.9722, Test: 0.9795\n",
      "Epoch: 039, Loss: 0.0132, Val: 0.9737, Test: 0.9817\n",
      "Epoch: 040, Loss: 0.0132, Val: 0.9754, Test: 0.9822\n",
      "Epoch: 041, Loss: 0.0120, Val: 0.9747, Test: 0.9822\n",
      "Epoch: 042, Loss: 0.0115, Val: 0.9752, Test: 0.9825\n",
      "Epoch: 043, Loss: 0.0103, Val: 0.9744, Test: 0.9814\n",
      "Epoch: 044, Loss: 0.0108, Val: 0.9752, Test: 0.9819\n",
      "Epoch: 045, Loss: 0.0099, Val: 0.9756, Test: 0.9826\n",
      "Epoch: 046, Loss: 0.0098, Val: 0.9762, Test: 0.9831\n",
      "Epoch: 047, Loss: 0.0094, Val: 0.9751, Test: 0.9817\n",
      "Epoch: 048, Loss: 0.0140, Val: 0.9736, Test: 0.9807\n",
      "Epoch: 049, Loss: 0.0125, Val: 0.9740, Test: 0.9808\n",
      "Epoch: 050, Loss: 0.0148, Val: 0.9702, Test: 0.9781\n",
      "Epoch: 051, Loss: 0.0248, Val: 0.9632, Test: 0.9730\n",
      "Epoch: 052, Loss: 0.0397, Val: 0.9556, Test: 0.9651\n",
      "Epoch: 053, Loss: 0.0523, Val: 0.9456, Test: 0.9579\n",
      "Epoch: 054, Loss: 0.0508, Val: 0.9501, Test: 0.9625\n",
      "Epoch: 055, Loss: 0.0501, Val: 0.9575, Test: 0.9689\n",
      "Epoch: 056, Loss: 0.0363, Val: 0.9595, Test: 0.9698\n",
      "Epoch: 057, Loss: 0.0248, Val: 0.9676, Test: 0.9769\n",
      "Epoch: 058, Loss: 0.0170, Val: 0.9744, Test: 0.9820\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m      7\u001b[0m val_f1 \u001b[38;5;241m=\u001b[39m test(val_loader_ppi)\n\u001b[0;32m----> 8\u001b[0m test_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader_ppi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m times\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m~/anaconda3/envs/gat/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     30\u001b[0m     ys\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m---> 31\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend((out \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     34\u001b[0m y, pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(ys, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(), torch\u001b[38;5;241m.\u001b[39mcat(preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/gat/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gat/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x))\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x))\n\u001b[0;32m---> 22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin3(x)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/gat/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gat/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gat/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py:322\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    320\u001b[0m         num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_nodes, x_dst\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    321\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_nodes\n\u001b[0;32m--> 322\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mremove_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m add_self_loops(\n\u001b[1;32m    325\u001b[0m         edge_index, edge_attr, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value,\n\u001b[1;32m    326\u001b[0m         num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n",
      "File \u001b[0;32m~/anaconda3/envs/gat/lib/python3.8/site-packages/torch_geometric/utils/loop.py:113\u001b[0m, in \u001b[0;36mremove_self_loops\u001b[0;34m(edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    110\u001b[0m     is_undirected \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mis_undirected\n\u001b[1;32m    112\u001b[0m mask \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 113\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[1;32m    116\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "times = []\n",
    "for epoch in tqdm(range(1, 101), desc='Epochs'):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    val_f1 = test(val_loader_ppi)\n",
    "    test_f1 = test(test_loader_ppi)\n",
    "    if i % 10 == 0 or i == n_epochs:  \n",
    "        save_checkpoint({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'metrics': {'train_loss' : loss,\n",
    "                       'val_f1' : val_f1,\n",
    "                       'test_f1' : test_f1},\n",
    "        }, filename=f\"ppi_e{str(i).zfill(3)}.pth\")\n",
    "\n",
    "    tqdm.write(f'tr_loss: {loss:.4f}, val_f1: {val_f1:.4f}, test_f1: {test_f1:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Training GAT for Link Prediction for PubMed Citation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GATv2Conv, GCNConv\n",
    "\n",
    "class GCNNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "class GATv2Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads=num_heads)\n",
    "        self.conv2 = GATv2Conv(hidden_channels, out_channels, heads=num_heads)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "    \n",
    "\n",
    "class GATv1Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads)\n",
    "        self.conv2 = GATConv(hidden_channels, out_channels, heads=num_heads)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6931, Val: 0.7090, Test: 0.7126\n",
      "Epoch: 002, Loss: 0.6925, Val: 0.5874, Test: 0.5994\n",
      "Epoch: 003, Loss: 0.6901, Val: 0.6524, Test: 0.6632\n",
      "Epoch: 004, Loss: 0.6846, Val: 0.6731, Test: 0.6842\n",
      "Epoch: 005, Loss: 0.6736, Val: 0.6767, Test: 0.6867\n",
      "Epoch: 006, Loss: 0.6576, Val: 0.8074, Test: 0.7962\n",
      "Epoch: 007, Loss: 0.6321, Val: 0.7952, Test: 0.7798\n",
      "Epoch: 008, Loss: 0.6053, Val: 0.8038, Test: 0.7904\n",
      "Epoch: 009, Loss: 0.5826, Val: 0.7928, Test: 0.7780\n",
      "Epoch: 010, Loss: 0.5786, Val: 0.8067, Test: 0.7930\n",
      "Epoch: 011, Loss: 0.5818, Val: 0.8072, Test: 0.7932\n",
      "Epoch: 012, Loss: 0.5814, Val: 0.8273, Test: 0.8145\n",
      "Epoch: 013, Loss: 0.5627, Val: 0.8418, Test: 0.8314\n",
      "Epoch: 014, Loss: 0.5507, Val: 0.8468, Test: 0.8382\n",
      "Epoch: 015, Loss: 0.5425, Val: 0.8439, Test: 0.8370\n",
      "Epoch: 016, Loss: 0.5426, Val: 0.8377, Test: 0.8329\n",
      "Epoch: 017, Loss: 0.5431, Val: 0.8324, Test: 0.8287\n",
      "Epoch: 018, Loss: 0.5457, Val: 0.8318, Test: 0.8283\n",
      "Epoch: 019, Loss: 0.5528, Val: 0.8349, Test: 0.8313\n",
      "Epoch: 020, Loss: 0.5470, Val: 0.8413, Test: 0.8370\n",
      "Epoch: 021, Loss: 0.5380, Val: 0.8471, Test: 0.8414\n",
      "Epoch: 022, Loss: 0.5348, Val: 0.8505, Test: 0.8438\n",
      "Epoch: 023, Loss: 0.5344, Val: 0.8512, Test: 0.8435\n",
      "Epoch: 024, Loss: 0.5327, Val: 0.8509, Test: 0.8420\n",
      "Epoch: 025, Loss: 0.5355, Val: 0.8502, Test: 0.8401\n",
      "Epoch: 026, Loss: 0.5342, Val: 0.8495, Test: 0.8392\n",
      "Epoch: 027, Loss: 0.5373, Val: 0.8496, Test: 0.8400\n",
      "Epoch: 028, Loss: 0.5336, Val: 0.8505, Test: 0.8415\n",
      "Epoch: 029, Loss: 0.5312, Val: 0.8527, Test: 0.8438\n",
      "Epoch: 030, Loss: 0.5338, Val: 0.8542, Test: 0.8459\n",
      "Epoch: 031, Loss: 0.5284, Val: 0.8545, Test: 0.8473\n",
      "Epoch: 032, Loss: 0.5273, Val: 0.8533, Test: 0.8473\n",
      "Epoch: 033, Loss: 0.5265, Val: 0.8531, Test: 0.8477\n",
      "Epoch: 034, Loss: 0.5272, Val: 0.8536, Test: 0.8483\n",
      "Epoch: 035, Loss: 0.5304, Val: 0.8538, Test: 0.8486\n",
      "Epoch: 036, Loss: 0.5292, Val: 0.8539, Test: 0.8490\n",
      "Epoch: 037, Loss: 0.5262, Val: 0.8543, Test: 0.8492\n",
      "Epoch: 038, Loss: 0.5277, Val: 0.8563, Test: 0.8505\n",
      "Epoch: 039, Loss: 0.5235, Val: 0.8576, Test: 0.8512\n",
      "Epoch: 040, Loss: 0.5243, Val: 0.8573, Test: 0.8509\n",
      "Epoch: 041, Loss: 0.5238, Val: 0.8563, Test: 0.8500\n",
      "Epoch: 042, Loss: 0.5245, Val: 0.8573, Test: 0.8506\n",
      "Epoch: 043, Loss: 0.5266, Val: 0.8581, Test: 0.8513\n",
      "Epoch: 044, Loss: 0.5249, Val: 0.8582, Test: 0.8518\n",
      "Epoch: 045, Loss: 0.5237, Val: 0.8578, Test: 0.8520\n",
      "Epoch: 046, Loss: 0.5252, Val: 0.8580, Test: 0.8525\n",
      "Epoch: 047, Loss: 0.5225, Val: 0.8584, Test: 0.8532\n",
      "Epoch: 048, Loss: 0.5213, Val: 0.8583, Test: 0.8534\n",
      "Epoch: 049, Loss: 0.5236, Val: 0.8582, Test: 0.8536\n",
      "Epoch: 050, Loss: 0.5222, Val: 0.8576, Test: 0.8533\n",
      "Epoch: 051, Loss: 0.5248, Val: 0.8579, Test: 0.8536\n",
      "Epoch: 052, Loss: 0.5223, Val: 0.8584, Test: 0.8541\n",
      "Epoch: 053, Loss: 0.5197, Val: 0.8585, Test: 0.8543\n",
      "Epoch: 054, Loss: 0.5227, Val: 0.8586, Test: 0.8541\n",
      "Epoch: 055, Loss: 0.5195, Val: 0.8588, Test: 0.8542\n",
      "Epoch: 056, Loss: 0.5218, Val: 0.8594, Test: 0.8548\n",
      "Epoch: 057, Loss: 0.5211, Val: 0.8597, Test: 0.8550\n",
      "Epoch: 058, Loss: 0.5200, Val: 0.8593, Test: 0.8546\n",
      "Epoch: 059, Loss: 0.5214, Val: 0.8593, Test: 0.8549\n",
      "Epoch: 060, Loss: 0.5208, Val: 0.8601, Test: 0.8558\n",
      "Epoch: 061, Loss: 0.5199, Val: 0.8597, Test: 0.8555\n",
      "Epoch: 062, Loss: 0.5171, Val: 0.8590, Test: 0.8551\n",
      "Epoch: 063, Loss: 0.5213, Val: 0.8598, Test: 0.8559\n",
      "Epoch: 064, Loss: 0.5192, Val: 0.8602, Test: 0.8564\n",
      "Epoch: 065, Loss: 0.5207, Val: 0.8597, Test: 0.8563\n",
      "Epoch: 066, Loss: 0.5189, Val: 0.8599, Test: 0.8564\n",
      "Epoch: 067, Loss: 0.5176, Val: 0.8603, Test: 0.8569\n",
      "Epoch: 068, Loss: 0.5185, Val: 0.8611, Test: 0.8577\n",
      "Epoch: 069, Loss: 0.5168, Val: 0.8614, Test: 0.8579\n",
      "Epoch: 070, Loss: 0.5172, Val: 0.8609, Test: 0.8577\n",
      "Epoch: 071, Loss: 0.5152, Val: 0.8628, Test: 0.8595\n",
      "Epoch: 072, Loss: 0.5152, Val: 0.8629, Test: 0.8599\n",
      "Epoch: 073, Loss: 0.5129, Val: 0.8621, Test: 0.8595\n",
      "Epoch: 074, Loss: 0.5135, Val: 0.8648, Test: 0.8620\n",
      "Epoch: 075, Loss: 0.5156, Val: 0.8650, Test: 0.8631\n",
      "Epoch: 076, Loss: 0.5111, Val: 0.8650, Test: 0.8633\n",
      "Epoch: 077, Loss: 0.5127, Val: 0.8671, Test: 0.8654\n",
      "Epoch: 078, Loss: 0.5112, Val: 0.8675, Test: 0.8668\n",
      "Epoch: 079, Loss: 0.5065, Val: 0.8680, Test: 0.8676\n",
      "Epoch: 080, Loss: 0.5060, Val: 0.8701, Test: 0.8696\n",
      "Epoch: 081, Loss: 0.5088, Val: 0.8707, Test: 0.8717\n",
      "Epoch: 082, Loss: 0.5041, Val: 0.8720, Test: 0.8732\n",
      "Epoch: 083, Loss: 0.5037, Val: 0.8726, Test: 0.8735\n",
      "Epoch: 084, Loss: 0.5022, Val: 0.8728, Test: 0.8751\n",
      "Epoch: 085, Loss: 0.5011, Val: 0.8730, Test: 0.8757\n",
      "Epoch: 086, Loss: 0.4985, Val: 0.8728, Test: 0.8753\n",
      "Epoch: 087, Loss: 0.5018, Val: 0.8723, Test: 0.8755\n",
      "Epoch: 088, Loss: 0.5003, Val: 0.8712, Test: 0.8751\n",
      "Epoch: 089, Loss: 0.5012, Val: 0.8716, Test: 0.8745\n",
      "Epoch: 090, Loss: 0.5046, Val: 0.8718, Test: 0.8758\n",
      "Epoch: 091, Loss: 0.5001, Val: 0.8731, Test: 0.8764\n",
      "Epoch: 092, Loss: 0.4997, Val: 0.8746, Test: 0.8775\n",
      "Epoch: 093, Loss: 0.4976, Val: 0.8751, Test: 0.8782\n",
      "Epoch: 094, Loss: 0.4985, Val: 0.8762, Test: 0.8790\n",
      "Epoch: 095, Loss: 0.4971, Val: 0.8764, Test: 0.8795\n",
      "Epoch: 096, Loss: 0.4974, Val: 0.8768, Test: 0.8793\n",
      "Epoch: 097, Loss: 0.4950, Val: 0.8780, Test: 0.8795\n",
      "Epoch: 098, Loss: 0.4959, Val: 0.8762, Test: 0.8795\n",
      "Epoch: 099, Loss: 0.4982, Val: 0.8781, Test: 0.8805\n",
      "Epoch: 100, Loss: 0.4962, Val: 0.8790, Test: 0.8801\n",
      "Final Test: 0.8801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data_pubmed.x, train_data_pubmed.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data_pubmed.edge_index, num_nodes=train_data_pubmed.num_nodes,\n",
    "        num_neg_samples=train_data_pubmed.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data_pubmed.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data_pubmed.edge_label,\n",
    "        train_data_pubmed.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['GCN','GAT','GAT-multi','GATv2','GATv2-multi']:\n",
    "    if model_name == 'GCN':\n",
    "        model = GCNNet(train_data_pubmed.num_features, 128, 64).to(device)\n",
    "    elif model_name == 'GAT':\n",
    "        model = GATv1Net(train_data_pubmed.num_features, 128, 64, 1).to(device)\n",
    "    elif model_name == 'GAT-multi':\n",
    "        model = GATv1Net(train_data_pubmed.num_features, 128, 64, 4).to(device)\n",
    "    elif model_name == 'GATv2':\n",
    "        model = GATv2Net(train_data_pubmed.num_features, 128, 64, 1).to(device)\n",
    "    elif model_name == 'GATv2-multi':\n",
    "        model = GATv2Net(train_data_pubmed.num_features, 128, 64, 4).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    best_val_auc = final_test_auc = 0\n",
    "    for epoch in tqdm(range(1, 101), desc='Epochs'):\n",
    "        loss = train()\n",
    "        val_auc = test(val_data_pubmed)\n",
    "        test_auc = test(test_data_pubmed)\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            final_test_auc = test_auc\n",
    "            save_checkpoint({\n",
    "                'epoch': i,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'metrics': {'train_loss' : loss,\n",
    "                           'val_auc' : val_auc,\n",
    "                           'test_auc' : test_auc},\n",
    "            }, filename=f\"PubMed_{model_name}_best.pth\")\n",
    "        if i % 10 == 0 or i == n_epochs:  \n",
    "            save_checkpoint({\n",
    "                'epoch': i,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'metrics': {'train_loss' : loss,\n",
    "                           'val_auc' : val_auc,\n",
    "                           'test_auc' : test_auc},\n",
    "            }, filename=f\"PubMed_{model_name}_e{str(i).zfill(3)}.pth\")\n",
    "        tqdm.write(f'tr_loss: {loss:.4f}, val_auc: {val_f1:.4f}, test_auc: {test_f1:.4f}')\n",
    "    \n",
    "    print(f'{model_name} Final Test: {final_test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX6bCcZNuxmz"
   },
   "source": [
    "# Results\n",
    "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
    "\n",
    "Please test and report results for all experiments that you run with:\n",
    "\n",
    "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
    "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjW9bCkouv8O"
   },
   "outputs": [],
   "source": [
    "# metrics to evaluate my model\n",
    "\n",
    "# plot figures to better show the results\n",
    "\n",
    "# it is better to save the numbers and figures for your presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EAWAy_LwHlV"
   },
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOdhGrbwwG71"
   },
   "outputs": [],
   "source": [
    "# compare you model with others\n",
    "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH75TNU71eRH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Discussion\n",
    "\n",
    "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
    "  * Make assessment that the paper is reproducible or not.\n",
    "  * Explain why it is not reproducible if your results are kind negative.\n",
    "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
    "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
    "  * What will you do in next phase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2VDXo5F4Frm"
   },
   "outputs": [],
   "source": [
    "# no code is required for this section\n",
    "'''\n",
    "if you want to use an image outside this notebook for explanaition,\n",
    "you can read and plot it here like the Scope of Reproducibility\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "\n",
    "Shaked Brody, Uri Alon, and Eran Yahav. How attentive are graph attention networks? In The Tenth\n",
    "International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29,\n",
    "2022. OpenReview.net, 2022. URL https://openreview.net/forum?id=F72ximsx7C1\n",
    "\n",
    "Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua\n",
    "Bengio. Graph attention networks. In 6th International Conference on Learning Representations,\n",
    "ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings.\n",
    "OpenReview.net, 2018. URL https://openreview.net/forum?id=rJXMpikCZ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmVuzQ724HbO"
   },
   "source": [
    "# Feel free to add new sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1oAKqszNlwEZwPa_BjHPqfcoWlikYBpi5",
     "timestamp": 1709153069464
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "gat",
   "language": "python",
   "name": "gat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
